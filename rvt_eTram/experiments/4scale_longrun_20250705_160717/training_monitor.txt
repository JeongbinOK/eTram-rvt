ğŸš€ Long-term 4-scale FPN Training Started
ğŸ“… Start Time: 2025-07-05T16:07:17.048817
ğŸ“ Experiment Directory: /home/oeoiewt/eTraM/rvt_eTram/experiments/4scale_longrun_20250705_160717
ğŸ¯ Target: 12-24 hour comprehensive training
ğŸ“Š Dataset: Extended sample (45 sequences, ~247k objects)
ğŸ—ï¸  Architecture: RVT + 4-scale FPN (strides: 4,8,16,32)
================================================================================

[2025-07-05 16:07:17] TRAINING COMMAND PREPARED
Command: python train.py model=rnndet dataset=gen4_extended_sample dataset.path=/home/oeoiewt/eTraM/rvt_eTram/data/gen4_cls8_extended_sample +experiment/gen4=default.yaml hardware.gpus=0 batch_size.train=6 batch_size.eval=2 hardware.num_workers.train=4 hardware.num_workers.eval=3 training.max_epochs=30 +model.head.num_classes=8 training.validation_interval=2000 training.checkpoint_interval=5000 model.postprocess.confidence_threshold=0.001 training.learning_rate=3.5e-5 training.warmup_epochs=2 training.experiment_dir=/home/oeoiewt/eTraM/rvt_eTram/experiments/4scale_longrun_20250705_160717 training.confusion_matrix_dir=/home/oeoiewt/eTraM/rvt_eTram/experiments/4scale_longrun_20250705_160717/confusion_matrices training.checkpoint_dir=/home/oeoiewt/eTraM/rvt_eTram/experiments/4scale_longrun_20250705_160717/checkpoints training.save_top_k=5 training.monitor_metric=val_loss training.early_stopping_patience=10 wandb.project_name=eTraM_4scale_FPN wandb.group_name=longterm_training_20250705 wandb.run_name=4scale_extended_160717 wandb.log_model=true wandb.watch_model=true
Initial GPU Memory: 1/24564 MB
Initial GPU Utilization: 0%
GPU Temperature: 37Â°C

[2025-07-05 16:07:17] TRAINING STARTED
[2025-07-05 16:07:20] Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.

[2025-07-05 16:07:20] TRAINING COMPLETED
Total Duration: 0.00 hours
Return Code: 1
