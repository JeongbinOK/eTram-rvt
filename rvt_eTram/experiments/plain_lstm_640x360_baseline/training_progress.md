# Plain LSTM 640x360 Baseline Experiment - Training Progress

## ì‹¤í—˜ ê°œìš”
- **ì‹¤í—˜ëª…**: plain_lstm_640x360_baseline
- **ëª©í‘œ**: RVT ë…¼ë¬¸ì˜ Plain LSTM êµ¬í˜„ìœ¼ë¡œ +1.1% mAP ê°œì„  ë‹¬ì„±
- **ì‹œì‘ ì‹œê°„**: 2025-07-24 16:23 KST
- **ì˜ˆìƒ ì†Œìš”ì‹œê°„**: ~5-6ì‹œê°„ (100K steps)

## ì•„í‚¤í…ì²˜ ë³€ê²½ì‚¬í•­
- **ê¸°ì¡´**: DWSConvLSTM2d (3x3 depthwise-separable convolution)
- **ì‹ ê·œ**: PlainLSTM2d (1x1 standard convolution)
- **ì´ë¡ ì  ê·¼ê±°**: RVT ë…¼ë¬¸ì—ì„œ Plain LSTMì´ ConvLSTM ëŒ€ë¹„ 1.1% mAP í–¥ìƒ ë° 50% íŒŒë¼ë¯¸í„° ê°ì†Œ

## í›ˆë ¨ ì„¤ì •
```yaml
model: maxvit_yolox/plain_lstm
dataset: gen4 (etram_cls8_sample)
training:
  max_steps: 100000
  batch_size: 6 (train), 2 (eval)
  sampling: stream
hardware:
  gpu: 0
  workers: 4 (train), 3 (eval)
```

## ì‹¤ì‹œê°„ í›ˆë ¨ ì§„í–‰ ìƒí™©

### ì´ˆê¸° ë‹¨ê³„ (0-1ë¶„)
- **Step 0-17**: Loss 56.1 â†’ í›ˆë ¨ ì‹œì‘
- **ì†ë„**: 1.45it/s (ì´ˆê¸° ë‹¨ê³„)
- **ìƒíƒœ**: Sanity check ì™„ë£Œ, ì •ìƒ ì‹œì‘

### ì•ˆì •í™” ë‹¨ê³„ (1-2ë¶„)
- **Step 17-330**: Loss 56.1 â†’ 10.1 (í¬ê²Œ ê°œì„ )
- **ì†ë„**: 4.27it/s (ì•ˆì •ì  ì†ë„)
- **ìƒíƒœ**: âœ… ì •ìƒì ì¸ ìˆ˜ë ´ íŒ¨í„´

## ì˜ˆìƒ ê²°ê³¼
- **Overall mAP**: 35.1% (34.02% baseline + 1.1% improvement)
- **Small Objects mAP**: 18.5% (17.28% baseline + proportional improvement)
- **Parameter Efficiency**: ~50% reduction vs ConvLSTM

## ëª¨ë‹ˆí„°ë§ í¬ì¸íŠ¸
1. **Loss ìˆ˜ë ´**: ì •ìƒì ìœ¼ë¡œ ê°ì†Œ ì¤‘ âœ…
2. **í›ˆë ¨ ì†ë„**: 4.27it/së¡œ ì–‘í˜¸ âœ…
3. **Memory Usage**: OOM ì—†ì´ ì•ˆì •ì  âœ…
4. **WandB Logging**: etram_enhanced í”„ë¡œì íŠ¸ì— ê¸°ë¡ ì¤‘

## ë‹¤ìŒ ë‹¨ê³„ ì¤€ë¹„
- Phase 2.1: Progressive Training êµ¬í˜„ ì¤€ë¹„
- Phase 2.2: Memory Optimization ê³„íš
- Phase 2.3: 1280x720 ê³ í•´ìƒë„ ì‹¤í—˜ ì¤€ë¹„

**Status**: ğŸŸ¢ í›ˆë ¨ ì •ìƒ ì§„í–‰ ì¤‘ (ETA: ~4-5ì‹œê°„ ë‚¨ìŒ)