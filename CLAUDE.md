# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This is the **eTraM (Event-based Traffic Monitoring Dataset)** repository, which contains implementations for event-based traffic monitoring using deep learning models. The project includes two main components:

1. **RVT (Recurrent Vision Transformers)** - Modified version for event-based object detection
2. **Ultralytics YOLO** - Modified version for event-based data

## Key Commands

### RVT Component (rvt_eTram/)

**Environment Setup:**
```bash
# Create environment using conda/mamba
conda env create -f environment.yaml
conda activate rvt
```

**Data Preprocessing:**
```bash
# Preprocess eTraM dataset to required format
python scripts/genx/preprocess_dataset.py <DATA_IN_PATH> <DATA_OUT_PATH> \
  conf_preprocess/representation/stacked_hist.yaml \
  conf_preprocess/extraction/const_duration.yaml \
  conf_preprocess/filter_gen4.yaml -ds gen4 -np <N_PROCESSES>
```

**Training:**
```bash
# Train RVT model
python train.py model=rnndet dataset=gen4 dataset.path=<DATA_DIR> \
  wandb.project_name=<WANDB_NAME> wandb.group_name=<WAND_GRP> \
  +experiment/gen4="default.yaml" hardware.gpus=0 batch_size.train=6 \
  batch_size.eval=2 hardware.num_workers.train=4 hardware.num_workers.eval=3 \
  training.max_epochs=20 dataset.train.sampling=stream +model.head.num_classes=8
```

**Evaluation:**
```bash
# Evaluate model
python validation.py dataset=gen4 dataset.path=${DATA_DIR} checkpoint=${CKPT_PATH} \
  use_test_set=${USE_TEST} hardware.gpus=${GPU_ID} +experiment/gen4="${MDL_CFG}.yaml" \
  batch_size.eval=8 model.postprocess.confidence_threshold=0.001
```

### Validation ì‹¤í–‰ ê°€ì´ë“œ (Troubleshooting)



#### 4. ê²€ì¦ëœ ì™„ì „í•œ Validation ëª…ë ¹ì–´
```bash
# ğŸ¯ ì„±ê³µì ì¸ Validation ì‹¤í–‰ í…œí”Œë¦¿
python validation.py \
  dataset=gen4 \
  model=maxvit_yolox/MODEL_CONFIG \
  checkpoint=SIMPLE_FILENAME.ckpt \
  use_test_set=false \
  hardware.gpus=0 \
  dataset.path=/home/oeoiewt/eTraM/rvt_eTram/data/etram_cls8_sample \
  +batch_size.train=6

# ì˜ˆì‹œ: Size-aware Loss ëª¨ë¸ ê²€ì¦
python validation.py \
  dataset=gen4 \
  model=maxvit_yolox/plain_lstm_sizeaware \
  checkpoint=/path/to/simple_filename.ckpt \
  use_test_set=false \
  hardware.gpus=0 \
  dataset.path=/home/oeoiewt/eTraM/rvt_eTram/data/etram_cls8_sample \
  +batch_size.train=6
```

#### 5. Screen Sessionì—ì„œ ì•ˆì „í•œ ì‹¤í–‰
```bash
# Screen session ìƒì„± ë° ì‹¤í–‰
screen -dmS validation_session
screen -S validation_session -p 0 -X stuff "source /home/oeoiewt/miniconda3/etc/profile.d/conda.sh && conda activate rvt && cd /home/oeoiewt/eTraM/rvt_eTram\n"
screen -S validation_session -p 0 -X stuff "python validation.py [PARAMETERS]\n"

# ì§„í–‰ ìƒí™© í™•ì¸
screen -S validation_session -X hardcopy /tmp/validation_status.txt
tail -20 /tmp/validation_status.txt
```

#### 6. Checkpoint íŒŒì¼ëª… ì²˜ë¦¬
```bash
# íŠ¹ìˆ˜ë¬¸ì(=, -, ë“±) í¬í•¨ëœ checkpoint íŒŒì¼ëª… ì²˜ë¦¬
ORIGINAL_CKPT="/path/epoch=001-step=100000-val_AP=0.31.ckpt"
SIMPLE_CKPT="/path/model_checkpoint.ckpt"
cp "$ORIGINAL_CKPT" "$SIMPLE_CKPT"

# ê°„ë‹¨í•œ íŒŒì¼ëª…ìœ¼ë¡œ validation ì‹¤í–‰
python validation.py checkpoint="$SIMPLE_CKPT" [OTHER_PARAMS]
```

### Ultralytics Component (ultralytics_eTram/)

**Environment Setup:**
```bash
# Install requirements
pip install -r requirements.txt
```

**Training/Inference:**
```bash
# Run YOLO training/inference
cd yolo_eTram
python main.py
```

## Memory Management

### Experimental Guidelines

**ì‹¤í—˜ ì§„í–‰ ì‹œ ì¤€ìˆ˜ì‚¬í•­:**
- í•­ìƒ `rvt_eTram/experiments/3scale_sizeaware_attention_100k/` ë””ë ‰í† ë¦¬ ì•„ë˜ì— ìˆëŠ” í˜•ì‹ë“¤ì„ ì§€ì¼œì„œ ì‹¤í—˜ ê²°ê³¼ë¥¼ ì •ë¦¬í•´ì¤˜
- ì‹¤í—˜ ê²°ê³¼ ë¬¸ì„œí™” ì‹œ í‘œì¤€ êµ¬ì¡° ìœ ì§€
- ì‹¤í—˜ ê°€ì„¤, ìˆ˜ì •ì‚¬í•­, ì„±ëŠ¥ ì§€í‘œë¥¼ ëª…í™•íˆ ê¸°ë¡

### ì‹¤í—˜ ë¬¸ì„œí™” í‘œì¤€

#### í•„ìˆ˜ íŒŒì¼ êµ¬ì¡°
```
experiments/3scale_sizeaware_attention_100k/
â”œâ”€â”€ experiment_hypothesis.txt      # ì‹¤í—˜ ê°€ì„¤ ë° ì´ë¡ ì  ê·¼ê±°
â”œâ”€â”€ modification_details.txt       # ì½”ë“œ ìˆ˜ì •ì‚¬í•­ ìƒì„¸ ê¸°ë¡  
â”œâ”€â”€ implementation_details.txt     # êµ¬í˜„ ì„¸ë¶€ì‚¬í•­ ë° ì•„í‚¤í…ì²˜
â”œâ”€â”€ experiment_config.yaml         # ì‹¤í—˜ ì„¤ì • íŒŒì¼ ë°±ì—…
â”œâ”€â”€ code_changes_summary.txt       # ì£¼ìš” ë³€ê²½ì‚¬í•­ ìš”ì•½
â”œâ”€â”€ training_command.txt           # ì‹¤ì œ ì‚¬ìš©í•œ í›ˆë ¨ ëª…ë ¹ì–´
â”œâ”€â”€ memory_test_results.txt        # ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸ ë° ìµœì í™” ê²°ê³¼
â”œâ”€â”€ experiment_results.json        # ìµœì¢… ì„±ëŠ¥ ê²°ê³¼ ë° ë¶„ì„
â”œâ”€â”€ checkpoints/final_model.ckpt   # ìµœì¢… í›ˆë ¨ëœ ëª¨ë¸
â”œâ”€â”€ confusion_matrices/            # Confusion matrix ì´ë¯¸ì§€ë“¤
â”œâ”€â”€ training_logs/                 # í›ˆë ¨ ë¡œê·¸ íŒŒì¼ë“¤
â””â”€â”€ validation_results/            # Validation ìƒì„¸ ê²°ê³¼
```

### ì„±ëŠ¥ í‰ê°€ ì§€í‘œ

#### ì •ëŸ‰ì  ì§€í‘œ
- **Overall mAP**: ì „ì²´ í‰ê·  ì •ë°€ë„
- **Small Objects mAP**: ì†Œí˜• ê°ì²´ ì„±ëŠ¥
- **AP50/AP75**: IoU thresholdë³„ ì„±ëŠ¥
- **AR (Average Recall)**: ì¬í˜„ìœ¨ ì§€í‘œ

### ì£¼ìš” ì‹¤í—˜ ì›ì¹™

1. **ì¬í˜„ì„± ë³´ì¥**: ëª¨ë“  ì„¤ì •ê³¼ ë³€ê²½ì‚¬í•­ ëª…í™•íˆ ê¸°ë¡
2. **ë‹¨ìˆœì„± ìœ ì§€**: ë¶ˆí•„ìš”í•œ ë³µì¡ì„± í”¼í•˜ê¸°
3. **ë°ì´í„° ì¤‘ì‹¬ ì ‘ê·¼**: ì•„í‚¤í…ì²˜ë³´ë‹¤ ë°ì´í„° í’ˆì§ˆ ê°œì„  ìš°ì„ 
4. **í‘œì¤€ ì ˆì°¨ ì¤€ìˆ˜**: ì‹¤í—˜ ë¬¸ì„œí™” ê°€ì´ë“œë¼ì¸ ì—„ê²©íˆ ë”°ë¥´ê¸°

## Validation í‘œì¤€ í”„ë¡œì„¸ìŠ¤

### ì„±ê³µì ì¸ Validation ì‹¤í–‰ ë°©ë²•

**í•µì‹¬ ì›ì¹™**: `+experiment/gen4='ì‹¤í—˜ì„¤ì •.yaml'` í˜•ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì „ì²´ ì„¤ì •ì„ ë¡œë“œ

**í‘œì¤€ ëª…ë ¹ì–´ í…œí”Œë¦¿**:
```bash
python validation.py \
  dataset=gen4 \
  checkpoint=CHECKPOINT_PATH \
  +experiment/gen4='EXPERIMENT_CONFIG.yaml' \
  hardware.gpus=0 \
  batch_size.eval=2 \
  hardware.num_workers.eval=1
```

### ì£¼ìš” í•´ê²° ë°©ë²•ë“¤

#### 1. Hydra Configuration ì˜¤ë¥˜ í•´ê²°
- **ë¬¸ì œ**: `ConfigAttributeError: Key 'train' is not in struct`
- **í•´ê²°**: ì „ì²´ ì‹¤í—˜ ì„¤ì • íŒŒì¼ ì‚¬ìš© (`+experiment/gen4='config.yaml'`)
- **ì˜ˆì‹œ**: `+experiment/gen4='plain_lstm_3scale_sizeaware_640x360.yaml'`

#### 2. Checkpoint ê²½ë¡œ ë¬¸ì œ
- **ë¬¸ì œ**: `FileNotFoundError` - checkpoint íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ
- **í•´ê²°**: ì‹¤ì œ checkpoint ìœ„ì¹˜ í™•ì¸ (`dummy/[ì‹¤í—˜ID]/checkpoints/`)
- **ëª…ë ¹**: `ls experiments/*/checkpoints/` ë˜ëŠ” `ls dummy/*/checkpoints/`

#### 3. Worker ì„¤ì • ì˜¤ë¥˜
- **ë¬¸ì œ**: `AssertionError: Each worker must at least get 'batch_size' number of datapipes`
- **í•´ê²°**: ë‚®ì€ workerì™€ batch size ì„¤ì •
- **ê¶Œì¥ê°’**: `batch_size.eval=2`, `hardware.num_workers.eval=1`

#### 4. Override ë¬¸ë²• ì˜¤ë¥˜
- **ë¬¸ì œ**: `Could not append to config` ë˜ëŠ” `ConfigKeyError`
- **í•´ê²°**: ì ì ˆí•œ override ì ‘ë‘ì‚¬ ì‚¬ìš©
  - ìƒˆ í‚¤ ì¶”ê°€: `+key=value`
  - ê¸°ì¡´ í‚¤ ê°•ì œ ë®ì–´ì“°ê¸°: `++key=value`
  - ì¼ë°˜ ì„¤ì •: `key=value`

### ê²€ì¦ëœ ì„±ê³µ ì‚¬ë¡€

#### Plain LSTM + Size-aware Loss
```bash
python validation.py \
  dataset=gen4 \
  checkpoint=dummy/zifokzkb/checkpoints/last_model.ckpt \
  +experiment/gen4='plain_lstm_3scale_sizeaware_640x360.yaml' \
  hardware.gpus=0 \
  batch_size.eval=2 \
  hardware.num_workers.eval=1
```

#### ì´ì „ ì‹¤í—˜ (3scale_sizeware_100k)
```bash
python validation.py \
  dataset=gen4 \
  dataset.path=/home/oeoiewt/eTraM/rvt_eTram/data/etram_cls8_sample \
  checkpoint=experiments/3scale_sizeaware_100k/checkpoints/final_model.ckpt \
  +experiment/gen4='3scale_sizeaware.yaml' \
  hardware.gpus=0 \
  batch_size.eval=2 \
  hardware.num_workers.eval=1
```

### í‘œì¤€ ì‹¤í—˜ ì›Œí¬í”Œë¡œìš°

#### Phase 1: ì‹¤í—˜ ê³„íš ë° ì„¤ì •
1. **ì‹¤í—˜ ê°€ì„¤ ë° ëª©í‘œ ì„¤ì •**
   - `experiments/[ì‹¤í—˜ëª…]/experiment_hypothesis.txt` ì‘ì„±
   - ì´ë¡ ì  ê·¼ê±° ë° ì˜ˆìƒ ê°œì„ ì  ëª…ì‹œ

2. **Configuration íŒŒì¼ ìƒì„±**
   - Model config: `config/model/maxvit_yolox/[ëª¨ë¸ëª…].yaml`
   - Experiment config: `config/experiment/gen4/[ì‹¤í—˜ëª…].yaml`
   - í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” (íŠ¹íˆ size-aware loss)

3. **ì‹¤í—˜ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±**
   ```bash
   mkdir -p experiments/[ì‹¤í—˜ëª…]/{checkpoints,confusion_matrices,training_logs,validation_results}
   ```

#### Phase 2: í›ˆë ¨ ì‹¤í–‰
1. **í›ˆë ¨ ëª…ë ¹ì–´ ì¤€ë¹„**
   ```bash
   python train.py dataset=gen4 \
     dataset.path=/home/oeoiewt/eTraM/rvt_eTram/data/etram_cls8_sample \
     +experiment/gen4='[ì‹¤í—˜ì„¤ì •].yaml' \
     hardware.gpus=0 \
     batch_size.train=6 batch_size.eval=2 \
     hardware.num_workers.train=4 hardware.num_workers.eval=3 \
     training.max_steps=100000 \
     dataset.train.sampling=stream \
     wandb.project_name=[í”„ë¡œì íŠ¸ëª…] \
     wandb.group_name=[ì‹¤í—˜ê·¸ë£¹ëª…]
   ```

2. **Screen ì„¸ì…˜ì—ì„œ í›ˆë ¨ ì‹¤í–‰**
   ```bash
   screen -dmS [ì‹¤í—˜ëª…]_100k
   screen -S [ì‹¤í—˜ëª…]_100k -p 0 -X stuff "cd /home/oeoiewt/eTraM/rvt_eTram\n"
   screen -S [ì‹¤í—˜ëª…]_100k -p 0 -X stuff "[í›ˆë ¨ëª…ë ¹ì–´]\n"
   ```

3. **í›ˆë ¨ ëª¨ë‹ˆí„°ë§**
   ```bash
   screen -r [ì‹¤í—˜ëª…]_100k  # ì§ì ‘ ëª¨ë‹ˆí„°ë§
   screen -list  # í™œì„± ì„¸ì…˜ í™•ì¸
   ```

#### Phase 3: í›ˆë ¨ ì™„ë£Œ í™•ì¸
1. **í›ˆë ¨ ìƒíƒœ í™•ì¸**
   ```bash
   screen -r [ì‹¤í—˜ëª…]_100k  # í›ˆë ¨ ì™„ë£Œ í™•ì¸
   ls dummy/*/checkpoints/  # checkpoint ìƒì„± í™•ì¸
   ```

2. **Checkpoint ë³µì‚¬ ë° ì •ë¦¬**
   ```bash
   cp dummy/[ì‹¤í—˜ID]/checkpoints/last_model.ckpt experiments/[ì‹¤í—˜ëª…]/checkpoints/
   cp confM/*.png experiments/[ì‹¤í—˜ëª…]/confusion_matrices/
   ```

#### Phase 4: Validation ì‹¤í–‰
1. **í‘œì¤€ Validation ëª…ë ¹ì–´**
   ```bash
   python validation.py \
     dataset=gen4 \
     checkpoint=dummy/[ì‹¤í—˜ID]/checkpoints/last_model.ckpt \
     +experiment/gen4='[ì‹¤í—˜ì„¤ì •].yaml' \
     hardware.gpus=0 \
     batch_size.eval=2 \
     hardware.num_workers.eval=1
   ```

2. **ê²°ê³¼ ì €ì¥**
   ```bash
   # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰í•˜ê³  ê²°ê³¼ ì €ì¥
   python validation.py [...] > experiments/[ì‹¤í—˜ëª…]/validation_results.txt 2>&1 &
   ```

3. **Validation ì§„í–‰ ëª¨ë‹ˆí„°ë§**
   ```bash
   tail -f experiments/[ì‹¤í—˜ëª…]/validation_results.txt  # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
   ps aux | grep validation  # í”„ë¡œì„¸ìŠ¤ ìƒíƒœ í™•ì¸
   ```

#### Phase 5: ê²°ê³¼ ë¶„ì„ ë° ë¬¸ì„œí™”
1. **ì„±ëŠ¥ ì§€í‘œ ì¶”ì¶œ**
   - Overall mAP, Small Objects AP, COCO metrics
   - í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ (íŠ¹íˆ Classes 2,3,4)
   - Confusion matrix ë¶„ì„

2. **ì‹¤í—˜ ê²°ê³¼ ë¬¸ì„œí™”**
   ```bash
   # í‘œì¤€ íŒŒì¼ êµ¬ì¡° ìƒì„±
   experiments/[ì‹¤í—˜ëª…]/
   â”œâ”€â”€ experiment_hypothesis.txt      # ì‹¤í—˜ ê°€ì„¤
   â”œâ”€â”€ modification_details.txt       # êµ¬í˜„ ì„¸ë¶€ì‚¬í•­
   â”œâ”€â”€ experiment_config.yaml         # ì„¤ì • ë°±ì—…
   â”œâ”€â”€ training_command.txt           # í›ˆë ¨ ëª…ë ¹ì–´
   â”œâ”€â”€ experiment_results.json        # ì„±ëŠ¥ ê²°ê³¼
   â”œâ”€â”€ checkpoints/final_model.ckpt   # ìµœì¢… ëª¨ë¸
   â”œâ”€â”€ confusion_matrices/            # í˜¼ëˆ í–‰ë ¬
   â””â”€â”€ validation_results/            # ê²€ì¦ ê²°ê³¼
   ```

3. **ì„±ëŠ¥ ë¹„êµ ë¶„ì„**
   - ì´ì „ ì‹¤í—˜ ëŒ€ë¹„ ê°œì„ ì  ì¸¡ì •
   - Small object detection íš¨ê³¼ ì •ëŸ‰í™”
   - ì‹¤íŒ¨ ì‚¬ë¡€ ë¶„ì„ ë° ê°œì„  ë°©í–¥ ì œì‹œ

#### Phase 6: ì‹¤í—˜ ì™„ë£Œ ë° ë‹¤ìŒ ë‹¨ê³„
1. **Git ì»¤ë°‹**
   ```bash
   git add experiments/[ì‹¤í—˜ëª…]/
   git commit -m "feat: complete [ì‹¤í—˜ëª…] experiment with [ì£¼ìš”ê²°ê³¼]"
   ```

2. **ë‹¤ìŒ ì‹¤í—˜ ê³„íš**
   - í˜„ì¬ ê²°ê³¼ ê¸°ë°˜ ê°œì„  ë°©í–¥ ì„¤ì •
   - í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì • ê³„íš
   - ì•„í‚¤í…ì²˜ ë³€ê²½ ê²€í† 

### ë¬¸ì œ í•´ê²° ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ì˜¬ë°”ë¥¸ experiment config íŒŒì¼ ì‚¬ìš©
- [ ] Checkpoint ê²½ë¡œ ì¡´ì¬ í™•ì¸
- [ ] ë‚®ì€ batch_sizeì™€ num_workers ì„¤ì •
- [ ] ì ì ˆí•œ Hydra override ë¬¸ë²• ì‚¬ìš©
- [ ] í™˜ê²½ ë³€ìˆ˜ ë° ê²½ë¡œ ì„¤ì • í™•ì¸

## Experimental Insights

### Key Findings

#### 1. ë³µì¡ì„± ì—­ì„¤ (Complexity Paradox)
- ë‹¨ìˆœí•œ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ì´ ì¢…ì¢… ë³µì¡í•œ ëª¨ë¸ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥
- ì•„í‚¤í…ì²˜ ê°œì„ ë³´ë‹¤ ë°ì´í„° í’ˆì§ˆì— ì§‘ì¤‘

#### 2. í•´ìƒë„ì˜ ì¤‘ìš”ì„±
- í•´ìƒë„ ì¦ê°€ê°€ ì•„í‚¤í…ì²˜ ê°œì„ ë³´ë‹¤ ë” í° ì„±ëŠ¥ í–¥ìƒ ê°€ëŠ¥
- 1280Ã—720 í•´ìƒë„ ì‹¤í—˜ ê°•ë ¥ ì¶”ì²œ

#### 3. Small Object Detection ì „ëµ
- ì´ë²¤íŠ¸ ê¸°ë°˜ ë°ì´í„°ì˜ í¬ì†Œì„± ê³ ë ¤
- ë°ì´í„° ì¦ê°• ë° í’ˆì§ˆ ê°œì„ ì— ì§‘ì¤‘

### Recommended Next Steps

1. í•´ìƒë„ ì¦ê°€ ì‹¤í—˜ (640Ã—360 â†’ 1280Ã—720)
2. ë°ì´í„° ì¦ê°• ê¸°ë²• ê°œë°œ
3. ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ì˜ ì„¸ë°€í•œ ìµœì í™”
4. ë‹¨ìˆœí•˜ê³  ëª…í™•í•œ ì ‘ê·¼ë²• ìœ ì§€

## ì‹¤í—˜ í‘œì¤€ ì›Œí¬í”Œë¡œìš°

### í‘œì¤€ ì‹¤í—˜ ì§„í–‰ ì ˆì°¨
```
1. ì‹¤í—˜ ê³„íš â†’ 2. Configuration ìƒì„± â†’ 3. ì‹¤í—˜ í´ë” êµ¬ì¡° â†’ 4. í›ˆë ¨ ì‹¤í–‰ â†’ 5. Validation â†’ 6. ë¬¸ì„œí™”
```

#### Phase 1: ì‹¤í—˜ ì¤€ë¹„
```bash
# 1. ì‹¤í—˜ í´ë” ìƒì„± (í‘œì¤€ êµ¬ì¡°)
mkdir -p experiments/EXPERIMENT_NAME/{checkpoints,confusion_matrices,training_logs,validation_results}

# 2. Configuration íŒŒì¼ ìƒì„±
# - config/model/maxvit_yolox/MODEL_CONFIG.yaml
# - config/experiment/gen4/EXPERIMENT_CONFIG.yaml

# 3. í•„ìˆ˜ ë¬¸ì„œ ìƒì„±
# - experiment_hypothesis.txt
# - training_command.txt  
# - modification_details.txt
# - code_changes_summary.txt
```

#### Phase 2: í›ˆë ¨ ì‹¤í–‰
```bash
# Screen sessionìœ¼ë¡œ í›ˆë ¨ ì‹œì‘
screen -dmS EXPERIMENT_NAME
screen -S EXPERIMENT_NAME -p 0 -X stuff "source /home/oeoiewt/miniconda3/etc/profile.d/conda.sh && conda activate rvt && cd /home/oeoiewt/eTraM/rvt_eTram\n"
screen -S EXPERIMENT_NAME -p 0 -X stuff "python train.py [TRAINING_PARAMETERS]\n"

# ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
screen -list | grep EXPERIMENT_NAME
screen -S EXPERIMENT_NAME -X hardcopy /tmp/training_status.txt
```

#### Phase 3: Validation ì‹¤í–‰ (í•µì‹¬ ê°œì„ ì‚¬í•­)
```bash
# 1. Checkpoint íŒŒì¼ëª… ê°„ë‹¨í™” (íŠ¹ìˆ˜ë¬¸ì ì œê±°)
cp "/path/epoch=001-step=100000-val_AP=0.31.ckpt" "/path/final_model.ckpt"

# 2. ê²€ì¦ëœ Validation ëª…ë ¹ì–´ (ì˜¤ë¥˜ ë°©ì§€)
python validation.py \
  dataset=gen4 \
  model=maxvit_yolox/MODEL_CONFIG \
  checkpoint=/path/final_model.ckpt \
  use_test_set=false \
  hardware.gpus=0 \
  dataset.path=/home/oeoiewt/eTraM/rvt_eTram/data/etram_cls8_sample \
  +batch_size.train=6

# 3. Screenì—ì„œ ì•ˆì „í•œ ì‹¤í–‰ (ì„ íƒì‚¬í•­)
screen -dmS validation_EXPERIMENT
screen -S validation_EXPERIMENT -p 0 -X stuff "source /home/oeoiewt/miniconda3/etc/profile.d/conda.sh && conda activate rvt && cd /home/oeoiewt/eTraM/rvt_eTram\n"
screen -S validation_EXPERIMENT -p 0 -X stuff "python validation.py [PARAMETERS]\n"
```

#### Phase 4: ê²°ê³¼ ì •ë¦¬ ë° ë¬¸ì„œí™”
```bash
# 1. Validation ê²°ê³¼ ì €ì¥
mkdir -p validation_results/EXPERIMENT_NAME
# validation output â†’ validation_results/EXPERIMENT_NAME/validation_output.log

# 2. Confusion Matrix ë³µì‚¬
cp confM/confusion_matrix_*.png experiments/EXPERIMENT_NAME/confusion_matrices/

# 3. ì‹¤í—˜ ê²°ê³¼ ë¬¸ì„œ ìƒì„±
# - experiment_results.json
# - metrics_summary.txt
# - ìƒì„¸ ì„±ëŠ¥ ë¶„ì„ ë¬¸ì„œ

# 4. Configuration ë°±ì—…
cp config/model/maxvit_yolox/MODEL_CONFIG.yaml experiments/EXPERIMENT_NAME/model_config.yaml
cp config/experiment/gen4/EXPERIMENT_CONFIG.yaml experiments/EXPERIMENT_NAME/experiment_config.yaml
```

### âš ï¸ Validation ì‹¤í–‰ ì‹œ ì£¼ì˜ì‚¬í•­
1. **Checkpoint íŒŒì¼ëª…**: `=` ê¸°í˜¸ê°€ í¬í•¨ëœ íŒŒì¼ëª…ì€ Hydra parsing ì˜¤ë¥˜ ë°œìƒ
2. **í•„ìˆ˜ íŒŒë¼ë¯¸í„°**: dataset, model, checkpoint, dataset.path ë°˜ë“œì‹œ í¬í•¨
3. **Batch Size**: ê¸°ì¡´ ì„¤ì •ì— ì—†ëŠ” ê²½ìš° `+batch_size.train=6` í˜•ì‹ ì‚¬ìš©
4. **Screen Session**: ì¥ì‹œê°„ ì‹¤í–‰ ì‹œ ì•ˆì „í•œ í™˜ê²½ ì œê³µ

## Validation Memory Guidelines

### Object Detection Validation ì§€ì¹¨

#### Validation ìˆ˜í–‰ ì‹œ í™•ì¸ ì‚¬í•­

- **Validation ëª©ì **: COCO small/medium/large mAPì™€ í´ë˜ìŠ¤ë³„ í¬ê¸°ë³„ mAP ë¶„ì„
- **í´ë˜ìŠ¤ í¬ê¸° ë§¤í•‘**:
  - Small Objects:
    - Class 0: Pedestrian
    - Class 2: Bicycle
    - Class 7: Wheelchair
  - Medium Objects:
    - Class 4: Motorbike
  - Large Objects:
    - Class 1: Car
    - Class 3: Bus
    - Class 5: Truck
    - Class 6: Tram

#### Validation ì‹¤í–‰ ì‹œ ì¶”ê°€ ì²´í¬í¬ì¸íŠ¸

- COCO ì „ì²´ mAP í™•ì¸
- í´ë˜ìŠ¤ë³„ mAP ë¶„ì„
  - Small object mAP íŠ¹ë³„ ê´€ì°°
  - Large object mAP ë¹„êµ
  - Medium object mAP ë¶„ì„

#### ê¶Œì¥ Validation ì„¸ë¶€ ì„¤ì •

```bash
python validation.py \
  dataset=gen4 \
  checkpoint=[CHECKPOINT] \
  +experiment/gen4=[CONFIG] \
  evaluation.coco_metrics=True \
  evaluation.class_wise_metrics=True \
  evaluation.object_size_metrics=True
```

### Validation ê²°ê³¼ ë¬¸ì„œí™” í…œí”Œë¦¿

```markdown
## Validation Results: [ì‹¤í—˜ëª…]

### Overall Performance
- Total mAP: X.XX%
- COCO mAP: 
  - Small Objects: X.XX%
  - Medium Objects: X.XX%
  - Large Objects: X.XX%

### Class-wise Performance
- Class 0 (Pedestrian): X.XX% 
- Class 1 (Car): X.XX%
...

### Size-aware Analysis
- Small Object Detection: ì·¨ì•½ì  ë° ê°œì„  ë°©í–¥
- Medium Object Detection: ì„±ëŠ¥ ë¶„ì„
- Large Object Detection: ê°•ì  ë° ì•ˆì •ì„±
```

### Experimental Results Tracking

#### New Memory Entry: Experiment Results Summary Template
- **Memory Location**: In the `experiment_results.json` file

```json
{
    "Model structure": "...",
    "Loss function": "...", 
    "Total mAP": "...",
    "COCO small mAP": "...",
    "COCO medium mAP": "...", 
    "COCO large mAP": "...",
    "Small class mAP": "...",
    "Medium class mAP": "...",
    "Large class mAP": "..."
}
```

These guidelines ensure a standardized approach to experimental tracking, validation, and documentation in the eTraM project.

## ğŸ† Completed Experiments Summary

### Overview
**Total Experiments**: 14 completed experiments (as of 2025-07-31)  
**Research Focus**: Event-based Traffic Monitoring with 8-class object detection  
**Dataset**: eTraM sample dataset (etram_cls8_sample)  
**Evaluation**: COCO-style mAP metrics with small/medium/large object analysis

### ğŸ“Š Performance Rankings

#### Overall mAP Rankings
1. **ğŸ¥‡ Plain LSTM + 4-scale FPN**: **34.6% mAP** (2h 24m training)
   - Best balanced performance across all object sizes
   - P1,P2,P3,P4 features for comprehensive small object coverage
   
2. **ğŸ¥ˆ Plain LSTM + Size-aware Loss + 960Ã—540**: **33.9% mAP** (3h 51m training)
   - **Best Small Objects AP: 18.9%** 
   - Optimal for small object detection applications
   
3. **ğŸ¥‰ Optimal Combination (4-scale + Size-aware + 960Ã—540)**: **32.2% mAP** (2h 16m training)
   - Complex combination with non-additive synergy effects
   - Valuable lesson in component interaction limitations
   
4. **Plain LSTM + Size-aware Loss**: **32.9% mAP** (5h 53m training)
   - Strong small object improvement (+55% vs baseline)
   
5. **Plain LSTM Baseline**: **28.2% mAP** (6h training)
   - Successful RVT paper implementation
   - Foundation for all subsequent improvements

#### Small Objects Detection Rankings
1. **ğŸ¯ Size-aware + 960Ã—540**: **18.9% AP** (ë² ì´ìŠ¤ë¼ì¸ 10.2% ëŒ€ë¹„ +85% í–¥ìƒ)
2. **4-scale FPN**: **16.7% AP** (+64% í–¥ìƒ)
3. **Optimal Combination**: **17.4% AP** (+70% í–¥ìƒ)
4. **Size-aware 640Ã—360**: **15.8% AP** (+55% í–¥ìƒ)

### ğŸ”¬ Experiment Categories

#### Architecture Experiments (6ê°œ)
- **Plain LSTM Baseline**: RVT ë…¼ë¬¸ ì„±ê³µì  ì¬í˜„ (28.2% mAP)
- **4-scale FPN**: ìµœê³  ì „ì²´ ì„±ëŠ¥ ë‹¬ì„± (34.6% mAP)
- **Size-aware Loss Variants**: Small object íŠ¹í™” (32.9% â†’ 33.9% mAP)
- **Lightweight Enhanced**: ë³µì¡ì„± ì—­ì„¤ ì…ì¦ (20.9% mAP)
- **Resolution Scaling**: 960Ã—540 í•´ìƒë„ íš¨ê³¼ ê²€ì¦

#### Class Imbalance Experiments (2ê°œ)
- **CB01 (ETRAMClassBalancedLoss)**: ë³µí•© ê¸°ë²• ì ìš© (23.5% mAP, 1h 39m)
- **CB03 (Simple Class-Balanced)**: 1/frequency ê°€ì¤‘ì¹˜ (22.3% mAP, 5h 52m)
- **Key Finding**: CB03ì´ Small Objectsì—ì„œ CB01 ëŒ€ë¹„ 43% ìš°ìˆ˜

### ğŸ’¡ í•µì‹¬ ë°œê²¬ì‚¬í•­

#### 1. ë³µì¡ì„± ì—­ì„¤ (Complexity Paradox)
ë‹¨ìˆœí•œ ì•„í‚¤í…ì²˜ê°€ ë³µì¡í•œ êµ¬ì¡°ë³´ë‹¤ ìš°ìˆ˜í•œ ê²½ìš°ê°€ ë¹ˆë²ˆí•¨ì„ ì…ì¦:
```
Simple 4-scale FPN:     34.6% mAP  â† ìµœê³  ì„±ëŠ¥
Complex Combination:    32.2% mAP  â† ì˜ˆìƒë³´ë‹¤ ë‚®ìŒ
Enhanced ConvLSTM:      20.9% mAP  â† ìµœì € ì„±ëŠ¥
```

#### 2. ì»´í¬ë„ŒíŠ¸ ì‹œë„ˆì§€ì˜ í•œê³„
ê°œë³„ ìµœì í™” ê¸°ë²•ë“¤ì˜ ì¡°í•©ì´ ì„ í˜•ì ìœ¼ë¡œ í•©ì³ì§€ì§€ ì•ŠìŒ:
- **ì˜ˆìƒ ì‹œë„ˆì§€**: 40.3% mAP (ì´ë¡ ì  ê³„ì‚°)
- **ì‹¤ì œ ê²°ê³¼**: 32.2% mAP (ì‹œë„ˆì§€ íš¨ìœ¨ 33%)

#### 3. Small Object Detection ì „ëµ
- **Size-aware Loss**: ê°€ì¥ íš¨ê³¼ì ì¸ ë‹¨ì¼ ê¸°ë²• (+55% í–¥ìƒ)
- **í•´ìƒë„ ì¦ê°€**: ì¶”ê°€ì  ì´ìµ ì œê³µ (+19.6% ì¶”ê°€ í–¥ìƒ)
- **4-scale FPN**: ê· í˜•ì¡íŒ ì„±ëŠ¥ìœ¼ë¡œ ëª¨ë“  ê°ì²´ í¬ê¸°ì— ë„ì›€

#### 4. í›ˆë ¨ íš¨ìœ¨ì„± ì¸ì‚¬ì´íŠ¸
- **ê°€ì¥ ë¹ ë¥¸ í›ˆë ¨**: CB01 (1h 39m, 23.5% mAP)
- **ìµœê³  ì„±ëŠ¥ ëŒ€ë¹„ ì‹œê°„**: 4-scale FPN (2h 24m, 34.6% mAP)
- **ê°€ì¥ ê¸´ í›ˆë ¨**: ë² ì´ìŠ¤ë¼ì¸ (6h, 28.2% mAP)

### ğŸ¯ Production ì¶”ì²œì‚¬í•­

#### Use Caseë³„ ìµœì  ëª¨ë¸
1. **ê· í˜•ì¡íŒ ì „ì²´ ì„±ëŠ¥**: Plain LSTM + 4-scale FPN (34.6% mAP)
2. **Small Objects íŠ¹í™”**: Plain LSTM + Size-aware + 960Ã—540 (18.9% Small AP)
3. **ë¹ ë¥¸ í›ˆë ¨ í•„ìš”**: CB01 Class-Balanced (1h 39m, 23.5% mAP)
4. **í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°**: CB03 Simple Class-Balanced (22.3% mAP)

#### ê°œë°œ ì§€ì¹¨
- **ë‹¨ìˆœì„± ìš°ì„ **: ë³µì¡í•œ ì¡°í•©ë³´ë‹¤ ê²€ì¦ëœ ë‹¨ì¼ ê¸°ë²• ì‚¬ìš©
- **ë°ì´í„° ì¤‘ì‹¬ ì ‘ê·¼**: ì•„í‚¤í…ì²˜ ë³µì¡í™”ë³´ë‹¤ ë°ì´í„° í’ˆì§ˆ ê°œì„ 
- **ì ì§„ì  ìµœì í™”**: í•œ ë²ˆì— í•˜ë‚˜ì”© ê°œì„ ì‚¬í•­ ì ìš© ë° ê²€ì¦

### ğŸ“ˆ í–¥í›„ ì—°êµ¬ ë°©í–¥

#### ì¦‰ì‹œ ì¶”ì§„ ê°€ëŠ¥í•œ ë°©í–¥
1. **4-scale FPN ê·¹í•œ ìµœì í™”**: í˜„ì¬ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
2. **1280Ã—720 í•´ìƒë„ ì‹¤í—˜**: ë” ë†’ì€ í•´ìƒë„ì—ì„œì˜ ì„±ëŠ¥ í•œê³„ íƒìƒ‰
3. **ë°ì´í„° ì¦ê°• ê¸°ë²•**: ì•„í‚¤í…ì²˜ ê°œì„ ë³´ë‹¤ ë°ì´í„° í’ˆì§ˆ í–¥ìƒ

#### ì¥ê¸° ì—°êµ¬ ë°©í–¥
1. **Sequential Optimization**: ë‹¨ê³„ë³„ ìµœì í™”ë¡œ ì‹œë„ˆì§€ íš¨ê³¼ ê·¹ëŒ€í™”
2. **Adaptive Component Weighting**: ë™ì  ê°€ì¤‘ì¹˜ ì¡°ì • ì‹œìŠ¤í…œ
3. **Event-based íŠ¹í™” ì•„í‚¤í…ì²˜**: ê¸°ì¡´ CNN ê¸°ë°˜ì„ ë„˜ì–´ì„  ìƒˆë¡œìš´ ì ‘ê·¼

### ğŸ“š ì‹¤í—˜ ë¬¸ì„œí™” í‘œì¤€
ëª¨ë“  ì‹¤í—˜ì€ ë‹¤ìŒ êµ¬ì¡°ë¡œ ì™„ì „íˆ ë¬¸ì„œí™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤:
```
experiments/[ì‹¤í—˜ëª…]/
â”œâ”€â”€ experiment_hypothesis.txt      # ê°€ì„¤ ë° ì´ë¡ ì  ê·¼ê±°
â”œâ”€â”€ experiment_results.json        # ì •ëŸ‰ì  ì„±ëŠ¥ ê²°ê³¼
â”œâ”€â”€ comprehensive_analysis.md       # ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ
â”œâ”€â”€ training_command.txt           # ì¬í˜„ ê°€ëŠ¥í•œ ëª…ë ¹ì–´
â”œâ”€â”€ checkpoints/final_model.ckpt   # í›ˆë ¨ëœ ëª¨ë¸
â”œâ”€â”€ confusion_matrices/            # ì„±ëŠ¥ ì‹œê°í™”
â””â”€â”€ validation_results/            # ìƒì„¸ ê²€ì¦ ê²°ê³¼
```

### ğŸ”¬ ì‹¤í—˜ ì¬í˜„ì„±
ëª¨ë“  ì‹¤í—˜ì€ ë‹¤ìŒì„ í†µí•´ ì™„ì „íˆ ì¬í˜„ ê°€ëŠ¥í•©ë‹ˆë‹¤:
- **Configuration Files**: Hydra ê¸°ë°˜ ì™„ì „í•œ ì„¤ì • ê´€ë¦¬
- **Training Commands**: Screen sessionê³¼ í•¨ê»˜ ê²€ì¦ëœ ëª…ë ¹ì–´
- **Environment**: `conda activate rvt` í™˜ê²½ì—ì„œ ì‹¤í–‰
- **Data Path**: `/home/oeoiewt/eTraM/rvt_eTram/data/etram_cls8_sample`

ì´ comprehensive experiment recordëŠ” Event-based Object Detection ë¶„ì•¼ì—ì„œ ì²´ê³„ì ì¸ ì—°êµ¬ ë°©ë²•ë¡ ê³¼ ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.